# Perplexity API Changelog

## [Update] - 2024-02-13
- The extension now uses the OpenAI client.
- Streaming capability has been added for receiving responses, ensuring real-time interaction.
- Prompts can now be edited directly in the extension's settings to allow for customization.
- Retrying with different models and temperature values is now supported, allowing for flexibility in generating outputs.
- Individual models can be selected in the extension settings for each command, enabling tailored usage according to your needs.
- Perplexity Online LLMs have been integrated into the `Ask AI` command.
- Removed `Compose Response` command as it can be achieved by using the `Ask AI` command.
- The `Add comments to code` command has been expanded and improved, now titled `Coding Assistant`.
- Added `Custom Action` command for creating custom actions.

## [Corrected Spelling] - 2024-02-12

## [Initial Version] - 2024-02-07

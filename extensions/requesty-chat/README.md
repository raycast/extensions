# Requesty Chat for Raycast

Chat with AI models through Requesty.ai directly from Raycast. Access powerful language models like Claude and GPT-4 with real-time cost tracking and chat history.

![Requesty Chat Screenshot](./media/screenshot1.png)

## Features

- **Multiple AI Models**: Access various AI models including Claude 3 Sonnet, GPT-4, and more
- **Real-time Cost Tracking**: Monitor your token usage and costs in real-time
- **Chat History**: Keep track of your conversations with automatic cost tracking
- **Smart Model Selection**: Easily switch between different AI models
- **Seamless Integration**: Chat directly from Raycast without switching context

## Prerequisites

- A Requesty.ai account
- An API key from Requesty.ai

## Installation

1. Install the extension from Raycast Store
2. Get your API key from [Requesty.ai](https://requesty.ai)
3. Open the extension settings in Raycast and enter your API key

## Getting Started

1. Open Raycast and select "New Chat" from Requesty Chat
2. Choose your preferred AI model
3. Start chatting!

## Commands

- **New Chat**: Start a new conversation with an AI model
- **Continue Chat**: Resume a previous conversation
- **Settings**: Configure your API key and preferences

## Models

The extension automatically fetches available models from Requesty.ai. Common models include:

- Anthropic Claude 3 Sonnet
- OpenAI GPT-4
- Google Gemini
- And more...

## Troubleshooting

If you encounter any issues:

1. Verify your API key is correctly set in the extension preferences
2. Check your internet connection
3. Ensure your Requesty.ai account is active and has sufficient credits

## Support

For support, please:

1. Check the [Requesty.ai documentation](https://docs.requesty.ai)
2. Contact support@requesty.ai
3. File an issue on GitHub

## Privacy

This extension only sends your messages to Requesty.ai's API. No data is stored outside of your local machine except for the chat content processed by the AI models.
